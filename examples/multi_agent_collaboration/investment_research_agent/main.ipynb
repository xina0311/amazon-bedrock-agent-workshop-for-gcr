{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7f7377-757b-4044-9028-f43acc0fa1f9",
   "metadata": {},
   "source": [
    "# AI Investment Research Assistant\n",
    "\n",
    "The instructions below guide you through the process of creating a supervisor agent and subagents for an investment research assistant. Each section explains the purpose of the code cells that follow.\n",
    "\n",
    "## PREREQUISITES:\n",
    "\n",
    "Follow instructions on README.md to setup the environment, deploy the web search stack, and deploy the stock data stack. Enable all necessary foundation models and attach permissions as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad1de4",
   "metadata": {},
   "source": [
    "#### Ensure that this cell is run before running any other cells in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r /home/sagemaker-user/amazon-bedrock-agent-samples/src/requirements.txt\n",
    "!pip install --upgrade boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a2cbb-7f7d-4a5b-88a3-4e1de0c52792",
   "metadata": {},
   "source": [
    "### Importing helper functions\n",
    "\n",
    "On following section, we're adding `bedrock_agent_helper.py` and `knowledge_base_helper` on Python path, so the files can be recognized and their functionalities can be invoked.\n",
    "\n",
    "Now, you're going to import from helper classes `bedrock_agent_helper.py` and `knowledge_base_helper.py`.\n",
    "\n",
    "All interactions with Bedrock will be handled by these classes.\n",
    "\n",
    "Following are methods that you're going to invoke on this notebook:\n",
    "\n",
    "On `agents.py`:\n",
    "- `create_agent`: Create a new agent and respective IAM roles\n",
    "- `invoke`: Execute agent\n",
    "\n",
    "On `knowledge_bases.py`:\n",
    "- `create_or_retrieve_knowledge_base`: Create Knowledge Base on Amazon Bedrock if it doesn't exist or get info about previous created.\n",
    "- `synchronize_data`: Read files on S3, convert text info into vectors and add that information on Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62176210-82c5-452e-aadb-1fb0d3c23467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "from IPython.display import JSON, IFrame, Video, display, clear_output\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "# Adjust the root path to go up 2 levels from the current working directory\n",
    "ROOT_PATH = Path.cwd().parents[2]\n",
    "sys.path.insert(0, str(ROOT_PATH))  # Insert at the beginning of sys.path\n",
    "\n",
    "# Importing custom modules\n",
    "from src.utils.bedrock_agent import (\n",
    "    Agent,\n",
    "    SupervisorAgent,\n",
    "    Task,\n",
    "    Guardrail,\n",
    "    region,\n",
    "    account_id,\n",
    "    agents_helper,\n",
    ")\n",
    "from src.utils.knowledge_base_helper import KnowledgeBasesForAmazonBedrock\n",
    "\n",
    "# Initialize the Knowledge Base helper\n",
    "kb_helper = KnowledgeBasesForAmazonBedrock()\n",
    "\n",
    "# Initialize boto3 client\n",
    "bedrock_client = boto3.client(\"bedrock\")\n",
    "# LLM = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "LLM = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "# LLM = \"amazon.nova-lite-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd376e-107c-4945-83e4-6695344b9815",
   "metadata": {},
   "source": [
    "## Setup Bedrock Data Automation Project (BDA)\n",
    "### Download multimodal data to be ingested into our knowledge base\n",
    "This may take ~5 minutes due to large file sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441fa48-da4b-48dc-86c8-6aca927b5b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir files/\n",
    "!curl -L -o files/Amazon-Quarterly-Earnings-Report-Q4-2024-Full-Call.wav https://s2.q4cdn.com/299287126/files/doc_financials/2024/q4/Amazon-Quarterly-Earnings-Report-Q4-2024-Full-Call-v1.wav\n",
    "!curl -L -o files/amazon2024_10k.pdf https://s2.q4cdn.com/299287126/files/doc_financials/2024/q4/e42c2068-bad5-4ab6-ae57-36ff8b2aeffd.pdf\n",
    "!curl -L -o files/amazon2024_q2_10Q.pdf https://s2.q4cdn.com/299287126/files/doc_financials/2024/q2/AMAZON-10Q-20240208.pdf\n",
    "!curl -L -o files/amazon2024_q3_10Q.pdf https://s2.q4cdn.com/299287126/files/doc_financials/2024/q3/76ba648c-eba4-4ec1-b571-4f5993feed2e.pdf\n",
    "!curl -L -o files/amazon2024_q1_10Q.pdf https://s2.q4cdn.com/299287126/files/doc_financials/2024/q1/04741924-2b6f-4934-91ab-1ccae56f0f9b.pdf\n",
    "!curl -L -o files/amazon2023_q1_10Q.pdf https://s2.q4cdn.com/299287126/files/doc_financials/2023/q1/394e4b27-bf11-4bcf-b650-2ac1b9fe2a14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4437465-a4df-4484-9d41-2f9e969d2aed",
   "metadata": {},
   "source": [
    "## Creating BDA Project\n",
    "\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple video/audio/image files that share the same settings.\n",
    "### Set up an S3 bucket for BDA and for the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536097b-5f67-448a-a168-69929cfa4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bda_client = boto3.client(\"bedrock-data-automation\", region_name=region)\n",
    "bda_runtime_client = boto3.client(\"bedrock-data-automation-runtime\", region_name=region)\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "kb_bucket_name = f\"multimodal-fsi-data-{region}-{account_id}\"\n",
    "\n",
    "try:\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=kb_bucket_name, \n",
    "        CreateBucketConfiguration={'LocationConstraint': region} # Comment this out if you are in us-east-1\n",
    "    )\n",
    "except ClientError as e:\n",
    "    # Check if bucket already exists\n",
    "    if e.response[\"Error\"][\"Code\"] in [\"BucketAlreadyOwnedByYou\"]:\n",
    "        print(\n",
    "            f\"Bucket {kb_bucket_name} already exists and is owned by you. No action taken.\"\n",
    "        )\n",
    "    else:\n",
    "        # For any other errors, raise the exception\n",
    "        raise\n",
    "\n",
    "\n",
    "# Create bucket for BDA input/output\n",
    "bda_bucket_name = f\"bda-processing-{region}-{account_id}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=bda_bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region} # Comment this out if you are in us-east-1\n",
    "    )\n",
    "except ClientError as e:\n",
    "    # Check if bucket already exists\n",
    "    if e.response[\"Error\"][\"Code\"] in [\"BucketAlreadyOwnedByYou\"]:\n",
    "        print(\n",
    "            f\"Bucket {bda_bucket_name} already exists and is owned by you. No action taken.\"\n",
    "        )\n",
    "    else:\n",
    "        # For any other errors, raise the exception\n",
    "        raise\n",
    "\n",
    "bda_bucket_name_input = f\"s3://{bda_bucket_name}/input/\"  # DBA input path\n",
    "bda_bucket_name_output = f\"s3://{bda_bucket_name}/output/\"  # DBA output path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe92b6e",
   "metadata": {},
   "source": [
    "Create a name for the BDA project. Deletes existing project, if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a48f9-bedd-4f60-a1f0-8865615b839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = f\"fsi-bda-{region}-{account_id}\"\n",
    "\n",
    "# delete project if it already exists\n",
    "projects_existing = [\n",
    "    project\n",
    "    for project in bda_client.list_data_automation_projects(projectStageFilter=\"ALL\")[\n",
    "        \"projects\"\n",
    "    ]\n",
    "    if project[\"projectName\"] == project_name\n",
    "]\n",
    "if len(projects_existing) > 0:\n",
    "    print(f\"Deleting existing project: {projects_existing[0]}\")\n",
    "    bda_client.delete_data_automation_project(\n",
    "        projectArn=projects_existing[0][\"projectArn\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef47b9",
   "metadata": {},
   "source": [
    "### Configure the BDA project\n",
    "For more information on creating/configuring BDA projects, take a look at our [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/bda-using-api.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37906e90-262c-4447-9473-70b2c003cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=project_name,\n",
    "    projectDescription=\"BDA video, audio, and document processing project\",\n",
    "    projectStage=\"DEVELOPMENT\",\n",
    "    standardOutputConfiguration={\n",
    "        \"video\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\",\n",
    "                    \"types\": [\"TEXT_DETECTION\", \"TRANSCRIPT\"],\n",
    "                },\n",
    "                \"boundingBox\": {\"state\": \"ENABLED\"},\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"VIDEO_SUMMARY\", \"CHAPTER_SUMMARY\", \"IAB\"],\n",
    "            },\n",
    "        },\n",
    "        \"audio\": {\n",
    "            \"extraction\": {\"category\": {\"state\": \"ENABLED\", \"types\": [\"TRANSCRIPT\"]}},\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"AUDIO_SUMMARY\", \"TOPIC_SUMMARY\", \"IAB\"],\n",
    "            },\n",
    "        },\n",
    "        \"document\": {\n",
    "            \"extraction\": {\n",
    "                \"granularity\": {\"types\": [\"DOCUMENT\", \"PAGE\", \"ELEMENT\"]},\n",
    "                \"boundingBox\": {\"state\": \"ENABLED\"},\n",
    "            },\n",
    "            \"generativeField\": {\"state\": \"ENABLED\"},\n",
    "            \"outputFormat\": {\n",
    "                \"textFormat\": {\"types\": [\"PLAIN_TEXT\"]},\n",
    "                \"additionalFileFormat\": {\"state\": \"ENABLED\"},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f7d3a",
   "metadata": {},
   "source": [
    "Retrieve and print out the ARN of the BDA project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5218635-037a-487a-a2ea-fecbfc801704",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA kb project ARN:\", kb_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9841b-705c-45e9-b05d-c87f997a7e32",
   "metadata": {},
   "source": [
    "## Process files by invoking BDA\n",
    "\n",
    "This may take ~10-15 minutes to process due to large size of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab17966-99b2-43c4-bd3b-7a99eb0363e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint_arn = None\n",
    "# If you want to use a blueprint, for example:\n",
    "# blueprint_arn = f\"arn:aws:bedrock:{region}:{account_id}:blueprint/bedrock-data-automation-public\"\n",
    "\n",
    "# Process files in your local folder (\"files/\")\n",
    "for root, dirs, files in os.walk(\"files/\"):\n",
    "    for file in files:\n",
    "        local_file_path = os.path.join(root, file)\n",
    "        s3_key_input = f\"input/{file}\"\n",
    "        s3_uri_input = f\"s3://{bda_bucket_name}/{s3_key_input}\"\n",
    "        # Use your output bucket URI as defined (make sure it ends with a slash if needed)\n",
    "        s3_uri_output = bda_bucket_name_output\n",
    "\n",
    "        print(f\"Uploading file {file} to {s3_uri_input}\")\n",
    "        s3_client.upload_file(local_file_path, bda_bucket_name, s3_key_input)\n",
    "\n",
    "        # Define the configurations following the working example:\n",
    "        inputConfiguration = {\"s3Uri\": s3_uri_input}\n",
    "        outputConfiguration = {\"s3Uri\": s3_uri_output}\n",
    "        # Use the project ARN as provided by create_data_automation_project() here:\n",
    "        dataAutomationConfiguration = {\"dataAutomationProjectArn\": kb_project_arn}\n",
    "\n",
    "        # Optionally, if you have a blueprint ARN, build a blueprints list. Otherwise, leave it out.\n",
    "        blueprints = (\n",
    "            [{\"blueprintArn\": blueprint_arn}] if blueprint_arn is not None else None\n",
    "        )\n",
    "\n",
    "        # Invoke the asynchronous BDA task\n",
    "        # Notice that we supply dataAutomationProfileArn at the top level and dataAutomationConfiguration with dataAutomationProjectArn.\n",
    "        kwargs = {}\n",
    "        if blueprints is not None:\n",
    "            kwargs[\"blueprints\"] = blueprints\n",
    "\n",
    "        bda_response = bda_runtime_client.invoke_data_automation_async(\n",
    "            dataAutomationConfiguration={\n",
    "                \"dataAutomationProjectArn\": kb_project_arn,  # your project ARN from create_data_automation_project()\n",
    "                \"stage\": \"DEVELOPMENT\",  # or \"LIVE\" if that's what you're using\n",
    "            },\n",
    "            inputConfiguration={\"s3Uri\": s3_uri_input},\n",
    "            outputConfiguration={\"s3Uri\": s3_uri_output},\n",
    "            dataAutomationProfileArn=f\"arn:aws:bedrock:{region}:{account_id}:data-automation-profile/us.data-automation-v1\",\n",
    "        )\n",
    "\n",
    "        invocation_arn = bda_response.get(\"invocationArn\")\n",
    "        print(\"BDA task started:\", invocation_arn)\n",
    "\n",
    "        # Poll for task completion\n",
    "        statusBDA = None\n",
    "        while statusBDA not in [\"Success\", \"ServiceError\", \"ClientError\"]:\n",
    "            status_response = bda_runtime_client.get_data_automation_status(\n",
    "                invocationArn=invocation_arn\n",
    "            )\n",
    "            statusBDA = status_response.get(\"status\")\n",
    "            clear_output(wait=True)\n",
    "            print(\n",
    "                f\"{datetime.now().strftime('%H:%M:%S')} : BDA task status: {statusBDA}\"\n",
    "            )\n",
    "            time.sleep(5)\n",
    "\n",
    "        output_config_uri = status_response.get(\"outputConfiguration\", {}).get(\"s3Uri\")\n",
    "        print(\"Output configuration file:\", output_config_uri)\n",
    "\n",
    "        # Prepare to download the result JSON from the output S3 URI.\n",
    "        # (Adjust the parsing as needed for your output structure)\n",
    "        out_result_key = output_config_uri.split(\"/job_metadata.json\", 1)[0].split(\n",
    "            f\"{bda_bucket_name}/\"\n",
    "        )[1]\n",
    "        out_result_key += \"/0/standard_output/0/result.json\"\n",
    "        local_result_file = f\"result_{file}.json\"\n",
    "        print(\"Downloading result file from key:\", out_result_key)\n",
    "        s3_client.download_file(bda_bucket_name, out_result_key, local_result_file)\n",
    "\n",
    "        # Finally, upload the result to your knowledge base bucket\n",
    "        kb_file = f\"data/result_{file}_kb.json\"\n",
    "        print(f\"Uploading file {local_result_file} to KB bucket\")\n",
    "        s3_client.upload_file(local_result_file, kb_bucket_name, kb_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635a93e-3c24-4a16-bc7f-4fb9e368ce76",
   "metadata": {},
   "source": [
    "### Set up functions to clean up agents and create a guardrail\n",
    "Function to delete agents and guardrails if they are already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980ac7f-43e3-43e5-af04-a3a77c06445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_agents():\n",
    "    agents_helper.delete_agent(\n",
    "        agent_name=\"investment_research_assistant\", delete_role_flag=True, verbose=True\n",
    "    )\n",
    "    agents_helper.delete_agent(\n",
    "        agent_name=\"news_agent\", delete_role_flag=True, verbose=True\n",
    "    )\n",
    "    agents_helper.delete_agent(\n",
    "        agent_name=\"quantitative_analysis_agent\", delete_role_flag=True, verbose=True\n",
    "    )\n",
    "    agents_helper.delete_agent(\n",
    "        agent_name=\"smart_summarizer_agent\", delete_role_flag=True, verbose=True\n",
    "    )\n",
    "    response = bedrock_client.list_guardrails()\n",
    "    for _gr in response[\"guardrails\"]:\n",
    "        if _gr[\"name\"] == \"no_bitcoin_guardrail\":\n",
    "            print(f\"Found guardrail: {_gr['id']}\")\n",
    "            guardrail_identifier = _gr[\"id\"]\n",
    "            bedrock_client.delete_guardrail(guardrailIdentifier=guardrail_identifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e51a0-e594-4392-af99-3d37e0805a80",
   "metadata": {},
   "source": [
    "#### Define Amazon Bedrock Guardrail\n",
    "[Amazon Bedrock Guardrails](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html) can implement safeguards for your generative AI applications based on your use cases and responsible AI policies. You can use guardrails for both user inputs and model responses with natural language. In this case, we are creating a guardrail to prevent cryptocurrencies from being discussed by our agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11417a19-275f-443b-9c11-d70f823b5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_guardrail():\n",
    "    return Guardrail(\n",
    "        \"no_bitcoin_guardrail\",\n",
    "        \"bitcoin_topic\",\n",
    "        \"No Bitcoin or cryptocurrency allowed in the analysis.\",\n",
    "        denied_topics=[\"bitcoin\", \"crypto\", \"cryptocurrency\"],\n",
    "        blocked_input_response=\"Sorry, this agent cannot discuss bitcoin.\",\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec897c16-774f-42c3-9e0e-6866316966ae",
   "metadata": {},
   "source": [
    "#### Delete old agents and guardrail if they exist, create new guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4f879-df4d-4d8c-a821-392401fcb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up_agents()\n",
    "Agent.set_force_recreate_default(True)\n",
    "no_bitcoin_guardrail = create_guardrail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bc6c7-0a5d-4801-8be5-0601a7df18ef",
   "metadata": {},
   "source": [
    "### Create subagents\n",
    "#### Create smart_summarizer_agent subagent\n",
    "This agent takes in output from other subagents, such as recent news and financial data, and synthesizes information into structured investment insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d52aa-b230-4071-9a4d-2fd11df94354",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_summarizer_agent = Agent.create(\n",
    "    name=\"smart_summarizer_agent\",\n",
    "    role=\"A financial analyst specializing in synthesizing stock market trends and financial news into structured investment insights. The agent produces fact-based summaries to support strategic decision-making.\",\n",
    "    goal=\"Analyze stock trends and market news to generate insights.\",\n",
    "    instructions=\"\"\"You are a Financial Analyst, responsible for analyzing stock trends and financial news to generate structured insights.\n",
    "                            Combine stock price trends with financial news to identify key patterns.\n",
    "                            Use your expertise to analyze macroeconomic indicators, company earnings, and market sentiment.\n",
    "                            Ensure responses are fact-driven, clearly structured, and cite sources where applicable.\n",
    "                            Do not generate financial advice—your role is to analyze and summarize available data objectively.\n",
    "                            Keep analyses concise and insightful, focusing on major trends and anomalies.\n",
    "                            Ensure answers are professional and coherent. No emojis should be displayed.\n",
    "                            **If given portfolio optimization pecentages, indicate that these are based on logic/math from the portfolio optimization tool, and are not considered financial advice**\"\"\",\n",
    "    llm=LLM,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91070679-79d3-409c-bbee-09d7d17d889d",
   "metadata": {},
   "source": [
    "#### Create quantitative_analysis subagent\n",
    "This agent queries and analyzes historical stock data, and builds optimized portfolio allocations based on user inputs like stock tickers, investment amount etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7edfef-dada-494b-b800-28ce0e5ec4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Lambda ARNs\n",
    "stock_data_tools_arn = f\"arn:aws:lambda:{region}:{account_id}:function:stock_data_tools\"\n",
    "\n",
    "quantitative_analysis_agent = Agent.create(\n",
    "    name=\"quantitative_analysis_agent\",\n",
    "    role=\"Financial Data Collector\",\n",
    "    goal=\"Retrieve real-time and historic stock prices as well as optimizing a portfolio given tickers.\",\n",
    "    instructions=\"\"\"You are a Stock Data and Portfolio Optimization Specialist. Your role is to retrieve real-time stock data and optimize investment portfolios.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Retrieving stock price data using the `stock_data_lookup` tool.\n",
    "2. Performing portfolio optimization when at least three stock tickers are provided.\n",
    "3. Enforcing the portfolio optimization rule: If fewer than three tickers are provided, inform the user that optimization requires at least three.\n",
    "\n",
    "Core behaviors:\n",
    "- Always retrieve stock data from `stock_data_lookup` before running portfolio optimization.\n",
    "- If portfolio optimization is requested, invoke `portfolio_optimization_action_group` only after retrieving stock data.\n",
    "- Do not attempt to interpret financial trends—focus solely on data retrieval and portfolio structuring.\n",
    "\"\"\",\n",
    "    tools=[\n",
    "        # Stock Data Lookup Tool\n",
    "        {\n",
    "            \"code\": stock_data_tools_arn,\n",
    "            \"definition\": {\n",
    "                \"name\": \"stock_data_lookup\",\n",
    "                \"description\": \"Gets the 1-month stock price history for a given stock ticker, formatted as JSON.\",\n",
    "                \"parameters\": {\n",
    "                    \"ticker\": {\n",
    "                        \"description\": \"The ticker to retrieve price history for\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        # Portfolio Optimization Tool\n",
    "        {\n",
    "            \"code\": stock_data_tools_arn,\n",
    "            \"definition\": {\n",
    "                \"name\": \"portfolio_optimization\",\n",
    "                \"description\": \"Optimizes a stock portfolio given a list of tickers and historical prices from the stock_data_lookup function.\",\n",
    "                \"parameters\": {\n",
    "                    \"tickers\": {\n",
    "                        \"description\": \"A comma-separated list of stock tickers to include in the portfolio\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    },\n",
    "                    \"prices\": {\n",
    "                        \"description\": \"A JSON object with dates as keys and stock prices as values\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    llm=LLM,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fd827-0d55-4ff7-b69d-ced7cf33317f",
   "metadata": {},
   "source": [
    "#### Create a knowledge base, create news_agent subagent, attach and syncronize the knowledge base\n",
    "This agent searches and retrieves relevant financial data like earnings reports, filings from the knowledge base for context. If information is not present in the knowledge base, it constructs a web query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a594df-9458-4fa1-966f-e8dbad3282b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_name = \"financial-analysis-kb\"\n",
    "kb_description = \"Access this knowledge base when needing to look up financial information like 10K reports, revenues, sales, net sales, loss and risks. Contains earnings calls.\"\n",
    "kb_id, ds_id = kb_helper.create_or_retrieve_knowledge_base(\n",
    "    kb_name=kb_name,\n",
    "    kb_description=kb_description,\n",
    "    data_bucket_name=kb_bucket_name,\n",
    "    embedding_model=\"amazon.titan-embed-text-v2:0\",\n",
    ")\n",
    "\n",
    "# Define Web Search Lambda ARN\n",
    "web_search_arn = f\"arn:aws:lambda:{region}:{account_id}:function:web_search\"\n",
    "\n",
    "\n",
    "news_agent = Agent.create(\n",
    "    name=\"news_agent\",\n",
    "    role=\"Market News Researcher\",\n",
    "    goal=\"Fetch from the knowledge base. Then if needed, fetch latest relevant news for a given stock based on a ticker.\",\n",
    "    instructions=f\"\"\"You are a Financial Document & News Analyst responsible for extracting structured insights from official financial reports and real-time news.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Extracting insights from earnings calls, SEC filings (10-K, 10-Q), and corporate press releases stored in the knowledge base (ID: {kb_id}).\n",
    "2. Summarizing financial reports with a focus on factual accuracy.\n",
    "3. Retrieving the latest financial news only **if the knowledge base lacks relevant information**.\n",
    "\n",
    "Core behaviors:\n",
    "- **Always check the knowledge base (ID: {kb_id}) first** before fetching external news.\n",
    "- **Avoid unnecessary web searches**—use external news sources only if the knowledge base lacks sufficient information.\n",
    "- Ensure all findings are **fact-based, neutral, and structured** for investment research.\n",
    "\"\"\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"code\": web_search_arn,\n",
    "            \"definition\": {\n",
    "                \"name\": \"web_search\",\n",
    "                \"description\": \"Searches the web for investment news and earnings reports.\",\n",
    "                \"parameters\": {\n",
    "                    \"search_query\": {\n",
    "                        \"description\": \"The query to search the web with\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    },\n",
    "                    \"target_website\": {\n",
    "                        \"description\": \"Specific website to search\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": False,\n",
    "                    },\n",
    "                    \"topic\": {\n",
    "                        \"description\": \"The topic being searched, such as 'news'\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": False,\n",
    "                    },\n",
    "                    \"days\": {\n",
    "                        \"description\": \"Number of days of history to search\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": False,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    kb_id=kb_id,\n",
    "    llm=LLM,\n",
    ")\n",
    "\n",
    "kb_helper.synchronize_data(kb_id, ds_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06e67d-38eb-4245-8aec-55c6f711d4d9",
   "metadata": {},
   "source": [
    "### Create the supervisor agent\n",
    "This supervisor agent orchestrates the overall investment research process by breaking down user prompts, delegating subtasks to specialized subagents, and consolidating their outputs to generate the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10b384-f7a9-49b7-b5ed-6d2583d25204",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_research_assistant = SupervisorAgent.create(\n",
    "    \"investment_research_assistant\",\n",
    "    role=\"Investment Research Assistant\",\n",
    "    goal=\"A seasoned investment research expert responsible for orchestrating subagents to conduct a comprehensive stock analysis. This agent synthesizes market news, stock data, and smart_summarizer insights into a structured investment report.\",\n",
    "    collaboration_type=\"SUPERVISOR\",\n",
    "    instructions=f\"\"\"You are an Investment Research Assistant, responsible for overseeing and synthesizing financial research from specialized agents. Your role is to coordinate subagents to produce structured investment insights.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Managing collaboration between subagents to retrieve and analyze financial data.\n",
    "2. Synthesizing stock trends, financial reports, and market news into a structured analysis.\n",
    "3. Delivering well-organized, fact-based investment insights with clear distinctions between data sources.\n",
    "\n",
    "Available subagents:\n",
    "- **news_agent**: Retrieves and summarizes the latest financial news.  \n",
    "  - **Always instruct news_agent to check the knowledge base (ID: {kb_id}) first before using external web searches**.\n",
    "- **quantitative_analysis_agent**: Provides real-time and historical stock prices.  \n",
    "  - For portfolio optimization, retrieve stock data via `stock_data_lookup` before calling `portfolio_optimization_action_group`.\n",
    "- **smart_summarizer_agent**: Synthesizes financial data and market trends into a structured investment insight.\n",
    "\n",
    "Core behaviors:\n",
    "- Only invoke a subagent when necessary. Do not invoke agent for information not requested by user.\n",
    "- Ensure responses are **well-structured, clearly formatted, and relevant to investor decision-making**.\n",
    "- Differentiate between financial news, technical stock analysis, and synthesized insights.\n",
    "\"\"\",\n",
    "    collaborator_agents=[\n",
    "        {\n",
    "            \"agent\": \"news_agent\",\n",
    "            \"instructions\": f\"Always check the knowledge base (ID: {kb_id}) first. Use this collaborator for finding news and analyzing specific documents.\",\n",
    "        },\n",
    "        {\n",
    "            \"agent\": \"quantitative_analysis_agent\",\n",
    "            \"instructions\": \"Use this collaborator for retrieving stock price history and performing portfolio optimization.\",\n",
    "        },\n",
    "        {\n",
    "            \"agent\": \"smart_summarizer_agent\",\n",
    "            \"instructions\": \"Use this collaborator for synthesizing stock trends, financial data, and generating structured investment insights.\",\n",
    "        },\n",
    "    ],\n",
    "    collaborator_objects=[\n",
    "        news_agent,\n",
    "        quantitative_analysis_agent,\n",
    "        smart_summarizer_agent,\n",
    "    ],\n",
    "    # guardrail=no_bitcoin_guardrail,\n",
    "    llm=LLM,\n",
    "    # verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce4447-5552-433a-bf48-01fd85e8fecc",
   "metadata": {},
   "source": [
    "### Example queries to the supervisor agent\n",
    "You may also test the multi-agent collaboration by querying the supervisor agent in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827737c-38b2-488f-8ef2-1802b1ba5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = (\n",
    "    \"what's AMZN stock price doing over the last week and relate that to recent news\"\n",
    ")\n",
    "print(f\"Request:\\n{request}\\n\")\n",
    "trace_level = \"core\"\n",
    "result = investment_research_assistant.invoke(\n",
    "    request,\n",
    "    enable_trace=False,\n",
    "    trace_level=trace_level,\n",
    ")\n",
    "print(f\"Final answer:\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355037e3-6d37-4a94-95e3-62e49bf0e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Optimize my portfolio with AMZN, MSFT, and GOOG\"\n",
    "print(f\"Request:\\n{request}\\n\")\n",
    "trace_level = \"core\"\n",
    "result = investment_research_assistant.invoke(\n",
    "    request,\n",
    "    enable_trace=False,\n",
    "    trace_level=trace_level,\n",
    ")\n",
    "print(f\"Final answer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea2496-490b-46e3-a411-2cd6cbd50d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Tell me about 2023 Q1 amazon earnings call.\"\n",
    "print(f\"Request:\\n{request}\\n\")\n",
    "trace_level = \"core\"\n",
    "result = investment_research_assistant.invoke(\n",
    "    request,\n",
    "    enable_trace=False,\n",
    "    trace_level=trace_level,\n",
    ")\n",
    "print(f\"Final answer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4ad76-8e0d-4118-8853-3c894187335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Analyze Amazon’s financial health based on the 2024 10k report. Calculate important financial ratios. Limit to 5 sentences\"\n",
    "print(f\"Request:\\n{request}\\n\")\n",
    "trace_level = \"outline\"\n",
    "result = investment_research_assistant.invoke(\n",
    "    request,\n",
    "    enable_trace=False,\n",
    "    trace_level=trace_level,\n",
    ")\n",
    "print(f\"Final answer:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a6bab",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Running this cell will delete the agents created from this notebook. To fully clean up this project, you must also delete the WebSearch and the StockDataTools stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915021d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up_agents()\n",
    "# Delete the WebSearch and StockDataTools stack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
